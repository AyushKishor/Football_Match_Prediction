{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing the Necessary Libraries"
      ],
      "metadata": {
        "id": "wKzCKwxahUFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "QXbVjc2Dhcne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Match, Odds and Current Form Data"
      ],
      "metadata": {
        "id": "HzKQO-_TMeXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "file_name = list(uploaded.keys())[0]\n",
        "df = pd.read_csv(file_name)\n",
        "\n",
        "\n",
        "# Preview(dataset)\n",
        "print(\"Dataset preview:\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "3YsNHaR7bNz6",
        "outputId": "95c1e94a-f1b2-4a42-e3a8-0c1aed262020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d9db3407-e1d0-4234-98fc-90c8319dd13e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d9db3407-e1d0-4234-98fc-90c8319dd13e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving starting_dataset.csv to starting_dataset.csv\n",
            "Dataset preview:\n",
            "   Matches        Date   HomeTeam    AwayTeam  FTHG  FTAG FTR  MW  HTGS  ATGS  \\\n",
            "0        0  2002-08-17  Blackburn  Sunderland     0     0   D   1     0     0   \n",
            "1        1  2002-08-17   Charlton     Chelsea     2     3   A   1     0     0   \n",
            "2        2  2002-08-17    Everton   Tottenham     2     2   D   1     0     0   \n",
            "3        3  2002-08-17     Fulham      Bolton     4     1   H   1     0     0   \n",
            "4        4  2002-08-17      Leeds    Man City     3     0   H   1     0     0   \n",
            "\n",
            "   ...  IWD  IWA    LBH   LBD   LBA    WHH    WHD    WHA  Home Win % (Before)  \\\n",
            "0  ...  3.1  3.8  1.615  3.25  5.00  1.660  3.465  4.500                  0.0   \n",
            "1  ...  3.0  2.2  2.800  3.20  2.20  2.750  3.100  2.415                  0.0   \n",
            "2  ...  3.0  2.7  2.250  3.20  2.75  2.300  3.255  2.750                  0.0   \n",
            "3  ...  3.1  3.8  1.833  3.20  3.75  1.806  3.200  4.330                  0.0   \n",
            "4  ...  3.2  4.2  1.615  3.50  4.50  1.743  3.300  4.500                  0.0   \n",
            "\n",
            "   Away Win % (Before)  \n",
            "0                  0.0  \n",
            "1                  0.0  \n",
            "2                  0.0  \n",
            "3                  0.0  \n",
            "4                  0.0  \n",
            "\n",
            "[5 rows x 47 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating Head-To-Head Data"
      ],
      "metadata": {
        "id": "ZMIlIE5Lx2OM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Initialize new columns for win percentages\n",
        "df['Home Win % (Before)'] = 0.0\n",
        "df['Away Win % (Before)'] = 0.0\n",
        "\n",
        "# Calculate win percentages for all prior head-to-head matches\n",
        "for idx, row in df.iterrows():\n",
        "    home_team = row['HomeTeam']\n",
        "    away_team = row['AwayTeam']\n",
        "    match_date = pd.to_datetime(row['Date'])\n",
        "\n",
        "    # Filter matches played before\n",
        "    previous_matches = df[\n",
        "        ((df['HomeTeam'] == home_team) & (df['AwayTeam'] == away_team)) |\n",
        "        ((df['HomeTeam'] == away_team) & (df['AwayTeam'] == home_team))\n",
        "    ]\n",
        "    previous_matches = previous_matches[pd.to_datetime(previous_matches['Date']) < match_date]\n",
        "\n",
        "    # Total matches played before this match\n",
        "    total_matches = len(previous_matches)\n",
        "\n",
        "    # Calculate home and away wins\n",
        "    if total_matches > 0:\n",
        "        # Home team wins\n",
        "        home_wins = sum(\n",
        "            ((previous_matches['HomeTeam'] == home_team) & (previous_matches['FTR'] == 'H')) |\n",
        "            ((previous_matches['AwayTeam'] == home_team) & (previous_matches['FTR'] == 'A'))\n",
        "        )\n",
        "\n",
        "        # Away team wins\n",
        "        away_wins = sum(\n",
        "            ((previous_matches['HomeTeam'] == away_team) & (previous_matches['FTR'] == 'H')) |\n",
        "            ((previous_matches['AwayTeam'] == away_team) & (previous_matches['FTR'] == 'A'))\n",
        "        )\n",
        "\n",
        "        # Calculate win percentages\n",
        "        home_win_percentage = (home_wins / total_matches) * 100\n",
        "        away_win_percentage = (away_wins / total_matches) * 100\n",
        "    else:\n",
        "        home_win_percentage = 0.0\n",
        "        away_win_percentage = 0.0\n",
        "\n",
        "\n",
        "    df.at[idx, 'Home Win % (Before)'] = home_win_percentage\n",
        "    df.at[idx, 'Away Win % (Before)'] = away_win_percentage\n",
        "\n",
        "\n",
        "updated_file_name = \"updated_final_dataset_with_win_percentages.csv\"\n",
        "df.to_csv(updated_file_name, index=False)\n",
        "print(f\"Updated dataset saved as '{updated_file_name}'.\")\n",
        "\n",
        "files.download(updated_file_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SfkF_k81wZh-",
        "outputId": "b707bf6f-c2ba-4232-9c4b-55b5c689e876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated dataset saved as 'updated_final_dataset_with_win_percentages.csv'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_de8ebb10-a5cf-4b47-be50-6d5b465dce4c\", \"updated_final_dataset_with_win_percentages.csv\", 1368805)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Softmax Regression without bookie odds"
      ],
      "metadata": {
        "id": "vlkPq6zbM5zA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "file_path = 'updated_final_dataset_with_win_percentages.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# target column (FTR) into numerical values\n",
        "df['FTR_encoded'] = df['FTR'].map({'H': 0, 'D': 1, 'A': 2})\n",
        "\n",
        "# Convert (HTFormPtsStr, ATFormPtsStr) to numerical representations\n",
        "df['HTFormPtsStr'] = df['HTFormPtsStr'].apply(lambda x: sum(3 if ch == 'W' else 1 if ch == 'D' else 0 for ch in x))\n",
        "df['ATFormPtsStr'] = df['ATFormPtsStr'].apply(lambda x: sum(3 if ch == 'W' else 1 if ch == 'D' else 0 for ch in x))\n",
        "\n",
        "# Define features\n",
        "features = [\n",
        "    'Home Win % (Before)', 'Away Win % (Before)',\n",
        "    'HTFormPts', 'ATFormPts',\n",
        "    'HTWinStreak3', 'HTWinStreak5', 'HTLossStreak3', 'HTLossStreak5',\n",
        "    'ATWinStreak3', 'ATWinStreak5', 'ATLossStreak3', 'ATLossStreak5',\n",
        "    'HTGC', 'ATGC',\n",
        "    'HTFormPtsStr', 'ATFormPtsStr',  # Recent form strings\n",
        "    'HomeTeamLP', 'AwayTeamLP',      # League positions\n",
        "    'DiffLP',                        # Difference in league positions\n",
        "    'HTP', 'ATP',                    # Team points\n",
        "    'HTGD', 'ATGD',                  # Goal differences\n",
        "    'DiffPts', 'DiffFormPts'         # Differences in points and form points\n",
        "]\n",
        "\n",
        "# target variable\n",
        "target = 'FTR_encoded'\n",
        "\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "# Stratified split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Standardize\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the Softmax Regression model\n",
        "softmax_model = LogisticRegression(\n",
        "    multi_class='multinomial',\n",
        "    solver='lbfgs',\n",
        "    max_iter=500,\n",
        "    C=0.5,\n",
        "    random_state=42\n",
        ")\n",
        "softmax_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_train = softmax_model.predict(X_train_scaled)\n",
        "y_pred_test = softmax_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate model\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train) * 100\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test) * 100\n",
        "\n",
        "\n",
        "class_mapping = {0: 'Home Win', 1: 'Draw', 2: 'Away Win'}\n",
        "target_names = [class_mapping[cls] for cls in sorted(y.unique())]\n",
        "classification_rep = classification_report(y_test, y_pred_test, target_names=target_names)\n",
        "\n",
        "# Bookmaker accuracy calculation\n",
        "def calculate_bookie_accuracy(df, bookies, index):\n",
        "    accuracies = {}\n",
        "    for bookie in bookies:\n",
        "        # Use odds for all bookmakers\n",
        "        bookie_predictions = df.loc[index, [f\"{bookie}H\", f\"{bookie}D\", f\"{bookie}A\"]].idxmin(axis=1)\n",
        "        bookie_predictions = bookie_predictions.map({f\"{bookie}H\": 'H', f\"{bookie}D\": 'D', f\"{bookie}A\": 'A'})\n",
        "        # Calculate accuracy against the actual results (FTR)\n",
        "        accuracy = (bookie_predictions == df.loc[index, 'FTR']).mean() * 100\n",
        "        accuracies[bookie] = accuracy\n",
        "    return accuracies\n",
        "\n",
        "# Calculate bookmaker accuracies for training and test data\n",
        "bookmakers = ['B365', 'LB', 'IW', 'WH']\n",
        "bookie_accuracies_train = calculate_bookie_accuracy(df, bookmakers, X_train.index)\n",
        "bookie_accuracies_test = calculate_bookie_accuracy(df, bookmakers, X_test.index)\n",
        "\n",
        "\n",
        "print(f\"Training Accuracy (Softmax): {train_accuracy:.2f}%\")\n",
        "print(f\"Testing Accuracy (Softmax): {test_accuracy:.2f}%\")\n",
        "print(\"\\nClassification Report (Softmax):\")\n",
        "print(classification_rep)\n",
        "\n",
        "print(\"\\nBookmaker Accuracies (Training Data):\")\n",
        "for bookie, accuracy in bookie_accuracies_train.items():\n",
        "    print(f\"{bookie}: {accuracy:.2f}%\")\n",
        "\n",
        "print(\"\\nBookmaker Accuracies (Test Data):\")\n",
        "for bookie, accuracy in bookie_accuracies_test.items():\n",
        "    print(f\"{bookie}: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "3MUlPLZXM8yY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbdab5c7-e515-42a3-aabd-f4aae7ebb972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy (Softmax): 53.54%\n",
            "Testing Accuracy (Softmax): 53.67%\n",
            "\n",
            "Classification Report (Softmax):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Home Win       0.56      0.82      0.66       557\n",
            "        Draw       0.44      0.01      0.03       303\n",
            "    Away Win       0.49      0.54      0.51       340\n",
            "\n",
            "    accuracy                           0.54      1200\n",
            "   macro avg       0.50      0.46      0.40      1200\n",
            "weighted avg       0.51      0.54      0.46      1200\n",
            "\n",
            "\n",
            "Bookmaker Accuracies (Training Data):\n",
            "B365: 54.31%\n",
            "LB: 54.40%\n",
            "IW: 54.33%\n",
            "WH: 52.79%\n",
            "\n",
            "Bookmaker Accuracies (Test Data):\n",
            "B365: 53.83%\n",
            "LB: 53.83%\n",
            "IW: 54.08%\n",
            "WH: 52.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Softmax Regression with 3 bookie odds"
      ],
      "metadata": {
        "id": "7jZX7cSrhrru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "file_path = 'updated_final_dataset_with_win_percentages.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Encode the target column (FTR) into numerical values\n",
        "df['FTR_encoded'] = df['FTR'].map({'H': 0, 'D': 1, 'A': 2})\n",
        "\n",
        "# Convert columns (HTFormPtsStr, ATFormPtsStr) to numerical representations\n",
        "df['HTFormPtsStr'] = df['HTFormPtsStr'].apply(lambda x: sum(3 if ch == 'W' else 1 if ch == 'D' else 0 for ch in x))\n",
        "df['ATFormPtsStr'] = df['ATFormPtsStr'].apply(lambda x: sum(3 if ch == 'W' else 1 if ch == 'D' else 0 for ch in x))\n",
        "\n",
        "# Define features\n",
        "features = [\n",
        "    'Home Win % (Before)', 'Away Win % (Before)',\n",
        "    'HTFormPts', 'ATFormPts',\n",
        "    'HTWinStreak3', 'HTWinStreak5', 'HTLossStreak3', 'HTLossStreak5',\n",
        "    'ATWinStreak3', 'ATWinStreak5', 'ATLossStreak3', 'ATLossStreak5',\n",
        "    'HTFormPtsStr', 'ATFormPtsStr',  # Recent form strings converted to numeric\n",
        "    'HomeTeamLP', 'AwayTeamLP',      # League positions\n",
        "    'DiffLP',                        # Difference in league positions\n",
        "    'IWH', 'IWD', 'IWA',             # IW bookmaker odds\n",
        "    'B365H', 'B365D', 'B365A',       # B365 bookmaker odds\n",
        "    'LBH', 'LBD', 'LBA',             # LB bookmaker odds\n",
        "    'HTP', 'ATP',                    # Team points\n",
        "    'HTGD', 'ATGD',                  # Goal differences\n",
        "    'DiffPts', 'DiffFormPts'         # Differences in points and form points\n",
        "]\n",
        "target = 'FTR_encoded'\n",
        "\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "# Handle missing values in target\n",
        "y = y.dropna()\n",
        "X = X.loc[y.index]\n",
        "\n",
        "# Stratified split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the Softmax Regression model\n",
        "softmax_model = LogisticRegression(\n",
        "    multi_class='multinomial',\n",
        "    solver='lbfgs',\n",
        "    max_iter=500,\n",
        "    C=0.5,\n",
        "    random_state=42\n",
        ")\n",
        "softmax_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_train = softmax_model.predict(X_train_scaled)\n",
        "y_pred_test = softmax_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train) * 100\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test) * 100\n",
        "\n",
        "\n",
        "class_mapping = {0: 'Home Win', 1: 'Draw', 2: 'Away Win'}\n",
        "target_names = [class_mapping[cls] for cls in sorted(y.unique())]\n",
        "classification_rep = classification_report(y_test, y_pred_test, target_names=target_names)\n",
        "\n",
        "# Bookmaker accuracy calculation\n",
        "def calculate_bookie_accuracy(df, bookies, index):\n",
        "    accuracies = {}\n",
        "    for bookie in bookies:\n",
        "        # Determine the bookmaker's prediction\n",
        "        bookie_predictions = df.loc[index, [f\"{bookie}H\", f\"{bookie}D\", f\"{bookie}A\"]].idxmin(axis=1)\n",
        "        bookie_predictions = bookie_predictions.map({f\"{bookie}H\": 'H', f\"{bookie}D\": 'D', f\"{bookie}A\": 'A'})\n",
        "        # Calculate accuracy against the actual results (FTR)\n",
        "        accuracy = (bookie_predictions == df.loc[index, 'FTR']).mean() * 100\n",
        "        accuracies[bookie] = accuracy\n",
        "    return accuracies\n",
        "\n",
        "# Calculate bookmaker accuracies for training and test data\n",
        "bookmakers_model = ['B365', 'IW', 'LB']\n",
        "bookmakers_excluded = ['WH']\n",
        "\n",
        "bookie_accuracies_train = calculate_bookie_accuracy(df, bookmakers_model, X_train.index)\n",
        "bookie_accuracies_test = calculate_bookie_accuracy(df, bookmakers_model, X_test.index)\n",
        "bookie_accuracies_excluded_test = calculate_bookie_accuracy(df, bookmakers_excluded, X_test.index)\n",
        "\n",
        "\n",
        "print(f\"Training Accuracy (Softmax): {train_accuracy:.2f}%\")\n",
        "print(f\"Testing Accuracy (Softmax): {test_accuracy:.2f}%\")\n",
        "print(\"\\nClassification Report (Softmax):\")\n",
        "print(classification_rep)\n",
        "\n",
        "print(\"\\nBookmaker Accuracies (Training Data - Included in Model):\")\n",
        "for bookie, accuracy in bookie_accuracies_train.items():\n",
        "    print(f\"{bookie}: {accuracy:.2f}%\")\n",
        "\n",
        "print(\"\\nBookmaker Accuracies (Test Data - Included in Model):\")\n",
        "for bookie, accuracy in bookie_accuracies_test.items():\n",
        "    print(f\"{bookie}: {accuracy:.2f}%\")\n",
        "\n",
        "print(\"\\nBookmaker Accuracies (Test Data - Excluded from Model):\")\n",
        "for bookie, accuracy in bookie_accuracies_excluded_test.items():\n",
        "    print(f\"{bookie}: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK66ZQPNhvbR",
        "outputId": "725ee4db-e5d7-45e4-c30a-6119be09719a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy (Softmax): 54.69%\n",
            "Testing Accuracy (Softmax): 53.50%\n",
            "\n",
            "Classification Report (Softmax):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Home Win       0.54      0.85      0.66       557\n",
            "        Draw       0.38      0.01      0.02       303\n",
            "    Away Win       0.51      0.48      0.50       340\n",
            "\n",
            "    accuracy                           0.54      1200\n",
            "   macro avg       0.48      0.45      0.39      1200\n",
            "weighted avg       0.49      0.54      0.45      1200\n",
            "\n",
            "\n",
            "Bookmaker Accuracies (Training Data - Included in Model):\n",
            "B365: 54.31%\n",
            "IW: 54.33%\n",
            "LB: 54.40%\n",
            "\n",
            "Bookmaker Accuracies (Test Data - Included in Model):\n",
            "B365: 53.83%\n",
            "IW: 54.08%\n",
            "LB: 53.83%\n",
            "\n",
            "Bookmaker Accuracies (Test Data - Excluded from Model):\n",
            "WH: 52.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM without bookie odds\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hjqyuFbUM85b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "file_path = 'updated_final_dataset_with_win_percentages.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Encode the target column (FTR) into numerical values\n",
        "df['FTR_encoded'] = df['FTR'].map({'H': 0, 'D': 1, 'A': 2})\n",
        "\n",
        "# Convert columns (HTFormPtsStr, ATFormPtsStr) to numerical representations\n",
        "df['HTFormPtsStr'] = df['HTFormPtsStr'].apply(\n",
        "    lambda x: sum(3 if ch == 'W' else 1 if ch == 'D' else 0 for ch in x) if isinstance(x, str) else 0\n",
        ")\n",
        "df['ATFormPtsStr'] = df['ATFormPtsStr'].apply(\n",
        "    lambda x: sum(3 if ch == 'W' else 1 if ch == 'D' else 0 for ch in x) if isinstance(x, str) else 0\n",
        ")\n",
        "\n",
        "\n",
        "numeric_columns = [\n",
        "    'Home Win % (Before)', 'Away Win % (Before)',\n",
        "    'HTGS', 'ATGS', 'HTGC', 'ATGC',\n",
        "    'HTFormPts', 'ATFormPts',\n",
        "    'HTWinStreak3', 'HTWinStreak5', 'HTLossStreak3', 'HTLossStreak5',\n",
        "    'ATWinStreak3', 'ATWinStreak5', 'ATLossStreak3', 'ATLossStreak5',\n",
        "    'HTFormPtsStr', 'ATFormPtsStr',\n",
        "    'HomeTeamLP', 'AwayTeamLP',\n",
        "    'DiffLP',\n",
        "    'HTP', 'ATP',\n",
        "    'HTGD', 'ATGD',\n",
        "    'DiffPts', 'DiffFormPts'\n",
        "]\n",
        "\n",
        "# Replace NaN values with 0 for numeric stability\n",
        "df.fillna(0, inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "X = df[numeric_columns]\n",
        "y = df['FTR_encoded']\n",
        "\n",
        "# Stratified split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the SVM model\n",
        "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_train = svm_model.predict(X_train_scaled)\n",
        "y_pred_test = svm_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train) * 100\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test) * 100\n",
        "\n",
        "\n",
        "unique_classes = sorted(y.unique())\n",
        "class_mapping = {0: 'Home Win', 1: 'Draw', 2: 'Away Win'}\n",
        "target_names = [class_mapping[cls] for cls in unique_classes]\n",
        "\n",
        "# Generate the classification report for testing data\n",
        "classification_rep = classification_report(y_test, y_pred_test, target_names=target_names)\n",
        "\n",
        "# Bookmaker accuracy calculation for both train and test sets\n",
        "def calculate_bookie_accuracy(df_subset, bookies):\n",
        "    accuracies = {}\n",
        "    for bookie in bookies:\n",
        "\n",
        "        bookie_predictions = df_subset[[f\"{bookie}H\", f\"{bookie}D\", f\"{bookie}A\"]].idxmin(axis=1)\n",
        "        bookie_predictions = bookie_predictions.map({f\"{bookie}H\": 'H', f\"{bookie}D\": 'D', f\"{bookie}A\": 'A'})\n",
        "        # Calculate accuracy against the actual results (FTR)\n",
        "        accuracy = (bookie_predictions == df_subset['FTR']).mean() * 100\n",
        "        accuracies[bookie] = accuracy\n",
        "    return accuracies\n",
        "\n",
        "\n",
        "train_indices = X_train.index\n",
        "test_indices = X_test.index\n",
        "\n",
        "bookmakers = ['B365', 'LB', 'IW', 'WH']\n",
        "bookie_accuracies_train = calculate_bookie_accuracy(df.loc[train_indices], bookmakers)\n",
        "bookie_accuracies_test = calculate_bookie_accuracy(df.loc[test_indices], bookmakers)\n",
        "\n",
        "\n",
        "print(f\"Training Accuracy (SVM): {train_accuracy:.2f}%\")\n",
        "print(f\"Testing Accuracy (SVM): {test_accuracy:.2f}%\")\n",
        "print(\"\\nClassification Report (SVM):\")\n",
        "print(classification_rep)\n",
        "\n",
        "print(\"\\nBookmaker Accuracies on Train Data:\")\n",
        "for bookie, accuracy in bookie_accuracies_train.items():\n",
        "    print(f\"{bookie}: {accuracy:.2f}%\")\n",
        "\n",
        "print(\"\\nBookmaker Accuracies on Test Data:\")\n",
        "for bookie, accuracy in bookie_accuracies_test.items():\n",
        "    print(f\"{bookie}: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "FZtvQgLLNEAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e215a99-7152-4810-ab10-343715e95917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy (SVM): 53.40%\n",
            "Testing Accuracy (SVM): 53.67%\n",
            "\n",
            "Classification Report (SVM):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Home Win       0.56      0.83      0.66       557\n",
            "        Draw       0.50      0.01      0.01       303\n",
            "    Away Win       0.49      0.54      0.51       340\n",
            "\n",
            "    accuracy                           0.54      1200\n",
            "   macro avg       0.52      0.46      0.40      1200\n",
            "weighted avg       0.52      0.54      0.46      1200\n",
            "\n",
            "\n",
            "Bookmaker Accuracies on Train Data:\n",
            "B365: 54.31%\n",
            "LB: 54.40%\n",
            "IW: 54.33%\n",
            "WH: 52.79%\n",
            "\n",
            "Bookmaker Accuracies on Test Data:\n",
            "B365: 53.83%\n",
            "LB: 53.83%\n",
            "IW: 54.08%\n",
            "WH: 52.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM with bookie odds"
      ],
      "metadata": {
        "id": "yTpfAGN8hwIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "file_path = 'updated_final_dataset_with_win_percentages.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Encode the target column (FTR) into numerical values\n",
        "df['FTR_encoded'] = df['FTR'].map({'H': 0, 'D': 1, 'A': 2})\n",
        "\n",
        "# Convert columns (HTFormPtsStr, ATFormPtsStr) to numerical representations\n",
        "df['HTFormPtsStr'] = df['HTFormPtsStr'].apply(\n",
        "    lambda x: sum(3 if ch == 'W' else 1 if ch == 'D' else 0 for ch in x) if isinstance(x, str) else 0\n",
        ")\n",
        "df['ATFormPtsStr'] = df['ATFormPtsStr'].apply(\n",
        "    lambda x: sum(3 if ch == 'W' else 1 if ch == 'D' else 0 for ch in x) if isinstance(x, str) else 0\n",
        ")\n",
        "\n",
        "# Ensure all required columns are numeric and fill NaN values with 0\n",
        "df.fillna(0, inplace=True)\n",
        "\n",
        "# Define feature columns\n",
        "features = [\n",
        "    'Home Win % (Before)', 'Away Win % (Before)',\n",
        "    'HTGS', 'ATGS', 'HTGC', 'ATGC',\n",
        "    'HTFormPts', 'ATFormPts',\n",
        "    'HTWinStreak3', 'HTWinStreak5', 'HTLossStreak3', 'HTLossStreak5',\n",
        "    'ATWinStreak3', 'ATWinStreak5', 'ATLossStreak3', 'ATLossStreak5',\n",
        "    'HTFormPtsStr', 'ATFormPtsStr',\n",
        "    'HomeTeamLP', 'AwayTeamLP',\n",
        "    'DiffLP',\n",
        "    'HTP', 'ATP',\n",
        "    'HTGD', 'ATGD',\n",
        "    'DiffPts', 'DiffFormPts',\n",
        "    'IWH', 'IWD', 'IWA',\n",
        "    'B365H', 'B365D', 'B365A',\n",
        "    'LBH', 'LBD', 'LBA'\n",
        "]\n",
        "target = 'FTR_encoded'\n",
        "\n",
        "# Prepare data\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "# Stratified split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the SVM model\n",
        "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_train = svm_model.predict(X_train_scaled)\n",
        "y_pred_test = svm_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train) * 100\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test) * 100\n",
        "\n",
        "# Dynamically generate target names based on unique classes in the test set\n",
        "unique_classes = sorted(y.unique())\n",
        "class_mapping = {0: 'Home Win', 1: 'Draw', 2: 'Away Win'}\n",
        "target_names = [class_mapping[cls] for cls in unique_classes]\n",
        "\n",
        "# classification report\n",
        "classification_rep = classification_report(y_test, y_pred_test, target_names=target_names)\n",
        "\n",
        "# Bookmaker accuracy calculation for both train and test sets\n",
        "def calculate_bookie_accuracy(df_subset, bookies):\n",
        "    accuracies = {}\n",
        "    for bookie in bookies:\n",
        "\n",
        "        bookie_predictions = df_subset[[f\"{bookie}H\", f\"{bookie}D\", f\"{bookie}A\"]].idxmin(axis=1)\n",
        "        bookie_predictions = bookie_predictions.map({f\"{bookie}H\": 'H', f\"{bookie}D\": 'D', f\"{bookie}A\": 'A'})\n",
        "        # Calculate accuracy against the actual results (FTR)\n",
        "        accuracy = (bookie_predictions == df_subset['FTR']).mean() * 100\n",
        "        accuracies[bookie] = accuracy\n",
        "    return accuracies\n",
        "\n",
        "# Calculate bookmaker accuracies for train and test data\n",
        "train_indices = X_train.index\n",
        "test_indices = X_test.index\n",
        "\n",
        "bookmakers_included = ['B365', 'IW', 'LB']\n",
        "bookmakers_excluded = ['WH']\n",
        "\n",
        "bookie_accuracies_train = calculate_bookie_accuracy(df.loc[train_indices], bookmakers_included + bookmakers_excluded)\n",
        "bookie_accuracies_test = calculate_bookie_accuracy(df.loc[test_indices], bookmakers_included + bookmakers_excluded)\n",
        "\n",
        "\n",
        "print(f\"Training Accuracy (SVM): {train_accuracy:.2f}%\")\n",
        "print(f\"Testing Accuracy (SVM): {test_accuracy:.2f}%\")\n",
        "print(\"\\nClassification Report (SVM):\")\n",
        "print(classification_rep)\n",
        "\n",
        "print(\"\\nBookmaker Accuracies on Train Data:\")\n",
        "for bookie, accuracy in bookie_accuracies_train.items():\n",
        "    print(f\"{bookie}: {accuracy:.2f}%\")\n",
        "\n",
        "print(\"\\nBookmaker Accuracies on Test Data:\")\n",
        "for bookie, accuracy in bookie_accuracies_test.items():\n",
        "    print(f\"{bookie}: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LJpokpPhx78",
        "outputId": "756070bd-59cc-49df-ff85-033a7ab22ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy (SVM): 53.48%\n",
            "Testing Accuracy (SVM): 52.50%\n",
            "\n",
            "Classification Report (SVM):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Home Win       0.51      0.92      0.66       557\n",
            "        Draw       0.00      0.00      0.00       303\n",
            "    Away Win       0.58      0.35      0.44       340\n",
            "\n",
            "    accuracy                           0.53      1200\n",
            "   macro avg       0.37      0.42      0.37      1200\n",
            "weighted avg       0.40      0.53      0.43      1200\n",
            "\n",
            "\n",
            "Bookmaker Accuracies on Train Data:\n",
            "B365: 54.31%\n",
            "IW: 54.33%\n",
            "LB: 54.40%\n",
            "WH: 52.79%\n",
            "\n",
            "Bookmaker Accuracies on Test Data:\n",
            "B365: 53.83%\n",
            "IW: 54.08%\n",
            "LB: 53.83%\n",
            "WH: 52.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NEURAL NETWORK without bookie odds"
      ],
      "metadata": {
        "id": "__DdnxOjgMPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "file_path = 'updated_final_dataset_with_win_percentages.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Encode the target column (FTR) into numerical values\n",
        "df['FTR_encoded'] = df['FTR'].map({'H': 0, 'D': 1, 'A': 2})\n",
        "\n",
        "# Convert columns (HTFormPtsStr, ATFormPtsStr) to numerical representations\n",
        "df['HTFormPtsStr'] = df['HTFormPtsStr'].apply(\n",
        "    lambda x: sum(3 if ch == 'W' else 1 if ch == 'D' else 0 for ch in x) if isinstance(x, str) else 0\n",
        ")\n",
        "df['ATFormPtsStr'] = df['ATFormPtsStr'].apply(\n",
        "    lambda x: sum(3 if ch == 'W' else 1 if ch == 'D' else 0 for ch in x) if isinstance(x, str) else 0\n",
        ")\n",
        "\n",
        "# Ensure all required columns are numeric and fill NaN values with 0\n",
        "df.fillna(0, inplace=True)\n",
        "\n",
        "# Define feature columns\n",
        "features = [\n",
        "    'Home Win % (Before)', 'Away Win % (Before)',\n",
        "    'HTGS', 'ATGS', 'HTGC', 'ATGC',\n",
        "    'HTFormPts', 'ATFormPts',\n",
        "    'HTWinStreak3', 'HTWinStreak5', 'HTLossStreak3', 'HTLossStreak5',\n",
        "    'ATWinStreak3', 'ATWinStreak5', 'ATLossStreak3', 'ATLossStreak5',\n",
        "    'HTFormPtsStr', 'ATFormPtsStr',\n",
        "    'HomeTeamLP', 'AwayTeamLP',\n",
        "    'DiffLP',\n",
        "    'HTP', 'ATP',\n",
        "    'HTGD', 'ATGD',\n",
        "    'DiffPts', 'DiffFormPts'\n",
        "]\n",
        "target = 'FTR_encoded'\n",
        "\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert the target variable to categorical format for DNN\n",
        "y_train_categorical = to_categorical(y_train, num_classes=3)\n",
        "y_test_categorical = to_categorical(y_test, num_classes=3)\n",
        "\n",
        "# Define the DNN model\n",
        "model = Sequential([\n",
        "    Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'),\n",
        "    Dropout(0.2),  # Prevent overfitting\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(3, activation='softmax')  # Output layer for 3 classes\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train_categorical,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "train_loss, train_accuracy = model.evaluate(X_train_scaled, y_train_categorical, verbose=0)\n",
        "train_accuracy *= 100\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=0)\n",
        "test_accuracy *= 100\n",
        "\n",
        "# Generate predictions for the test set\n",
        "y_pred_test_prob = model.predict(X_test_scaled)\n",
        "y_pred_test = np.argmax(y_pred_test_prob, axis=1)\n",
        "\n",
        "# Generate classification report\n",
        "class_mapping = {0: 'Home Win', 1: 'Draw', 2: 'Away Win'}\n",
        "target_names = [class_mapping[cls] for cls in sorted(y.unique())]\n",
        "classification_rep = classification_report(y_test, y_pred_test, target_names=target_names)\n",
        "\n",
        "# Bookmaker accuracy calculation\n",
        "def calculate_bookie_accuracy(df_subset, bookies):\n",
        "    accuracies = {}\n",
        "    for bookie in bookies:\n",
        "\n",
        "        bookie_predictions = df_subset[[f\"{bookie}H\", f\"{bookie}D\", f\"{bookie}A\"]].idxmin(axis=1)\n",
        "        bookie_predictions = bookie_predictions.map({f\"{bookie}H\": 'H', f\"{bookie}D\": 'D', f\"{bookie}A\": 'A'})\n",
        "        # Calculate accuracy against the actual results (FTR)\n",
        "        accuracy = (bookie_predictions == df_subset['FTR']).mean() * 100\n",
        "        accuracies[bookie] = accuracy\n",
        "    return accuracies\n",
        "\n",
        "# Calculate bookmaker accuracies for test data\n",
        "train_indices = X_train.index\n",
        "test_indices = X_test.index\n",
        "bookmakers = ['B365', 'LB', 'IW', 'WH']\n",
        "\n",
        "bookie_accuracies_train = calculate_bookie_accuracy(df.loc[train_indices], bookmakers)\n",
        "bookie_accuracies_test = calculate_bookie_accuracy(df.loc[test_indices], bookmakers)\n",
        "\n",
        "\n",
        "print(f\"Training Accuracy (DNN): {train_accuracy:.2f}%\")\n",
        "print(f\"Testing Accuracy (DNN): {test_accuracy:.2f}%\")\n",
        "print(\"\\nClassification Report (DNN):\")\n",
        "print(classification_rep)\n",
        "\n",
        "print(\"\\nBookmaker Accuracies on Train Data:\")\n",
        "for bookie, accuracy in bookie_accuracies_train.items():\n",
        "    print(f\"{bookie}: {accuracy:.2f}%\")\n",
        "\n",
        "print(\"\\nBookmaker Accuracies on Test Data:\")\n",
        "for bookie, accuracy in bookie_accuracies_test.items():\n",
        "    print(f\"{bookie}: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-Gy9zfqgOcL",
        "outputId": "feea8f4b-391d-486a-af06-da1262e9cdcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4867 - loss: 1.0248 - val_accuracy: 0.5188 - val_loss: 0.9921\n",
            "Epoch 2/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5381 - loss: 0.9778 - val_accuracy: 0.5260 - val_loss: 0.9851\n",
            "Epoch 3/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5407 - loss: 0.9749 - val_accuracy: 0.5250 - val_loss: 0.9855\n",
            "Epoch 4/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5216 - loss: 0.9768 - val_accuracy: 0.5323 - val_loss: 0.9889\n",
            "Epoch 5/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5458 - loss: 0.9575 - val_accuracy: 0.5292 - val_loss: 0.9861\n",
            "Epoch 6/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5366 - loss: 0.9668 - val_accuracy: 0.5281 - val_loss: 0.9770\n",
            "Epoch 7/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5362 - loss: 0.9664 - val_accuracy: 0.5240 - val_loss: 0.9877\n",
            "Epoch 8/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5356 - loss: 0.9726 - val_accuracy: 0.5281 - val_loss: 0.9828\n",
            "Epoch 9/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5332 - loss: 0.9735 - val_accuracy: 0.5229 - val_loss: 0.9904\n",
            "Epoch 10/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5522 - loss: 0.9528 - val_accuracy: 0.5240 - val_loss: 0.9831\n",
            "Epoch 11/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5483 - loss: 0.9566 - val_accuracy: 0.5250 - val_loss: 0.9836\n",
            "Epoch 12/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5491 - loss: 0.9648 - val_accuracy: 0.5198 - val_loss: 0.9886\n",
            "Epoch 13/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5320 - loss: 0.9722 - val_accuracy: 0.5260 - val_loss: 0.9864\n",
            "Epoch 14/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5409 - loss: 0.9617 - val_accuracy: 0.5260 - val_loss: 0.9872\n",
            "Epoch 15/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5620 - loss: 0.9470 - val_accuracy: 0.5219 - val_loss: 0.9913\n",
            "Epoch 16/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5598 - loss: 0.9429 - val_accuracy: 0.5135 - val_loss: 0.9894\n",
            "Epoch 17/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5603 - loss: 0.9387 - val_accuracy: 0.5010 - val_loss: 0.9974\n",
            "Epoch 18/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5505 - loss: 0.9410 - val_accuracy: 0.5146 - val_loss: 0.9973\n",
            "Epoch 19/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5540 - loss: 0.9503 - val_accuracy: 0.5125 - val_loss: 0.9944\n",
            "Epoch 20/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5691 - loss: 0.9243 - val_accuracy: 0.5188 - val_loss: 0.9934\n",
            "Epoch 21/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5687 - loss: 0.9236 - val_accuracy: 0.5146 - val_loss: 0.9975\n",
            "Epoch 22/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5620 - loss: 0.9330 - val_accuracy: 0.5135 - val_loss: 0.9981\n",
            "Epoch 23/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5678 - loss: 0.9293 - val_accuracy: 0.5083 - val_loss: 1.0012\n",
            "Epoch 24/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5838 - loss: 0.9191 - val_accuracy: 0.5073 - val_loss: 1.0021\n",
            "Epoch 25/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5630 - loss: 0.9216 - val_accuracy: 0.5156 - val_loss: 1.0075\n",
            "Epoch 26/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5607 - loss: 0.9239 - val_accuracy: 0.5167 - val_loss: 0.9957\n",
            "Epoch 27/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5832 - loss: 0.9104 - val_accuracy: 0.5083 - val_loss: 1.0001\n",
            "Epoch 28/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5725 - loss: 0.9050 - val_accuracy: 0.5135 - val_loss: 1.0092\n",
            "Epoch 29/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5760 - loss: 0.9004 - val_accuracy: 0.5042 - val_loss: 1.0116\n",
            "Epoch 30/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5870 - loss: 0.8989 - val_accuracy: 0.4958 - val_loss: 1.0057\n",
            "Epoch 31/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5787 - loss: 0.9148 - val_accuracy: 0.5073 - val_loss: 1.0032\n",
            "Epoch 32/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5734 - loss: 0.9139 - val_accuracy: 0.4979 - val_loss: 1.0163\n",
            "Epoch 33/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5848 - loss: 0.8981 - val_accuracy: 0.5042 - val_loss: 1.0176\n",
            "Epoch 34/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5873 - loss: 0.8792 - val_accuracy: 0.5115 - val_loss: 1.0049\n",
            "Epoch 35/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5791 - loss: 0.8932 - val_accuracy: 0.5052 - val_loss: 1.0222\n",
            "Epoch 36/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5924 - loss: 0.8843 - val_accuracy: 0.5063 - val_loss: 1.0151\n",
            "Epoch 37/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5880 - loss: 0.8882 - val_accuracy: 0.4969 - val_loss: 1.0242\n",
            "Epoch 38/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5981 - loss: 0.8860 - val_accuracy: 0.4979 - val_loss: 1.0228\n",
            "Epoch 39/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5926 - loss: 0.8824 - val_accuracy: 0.5042 - val_loss: 1.0309\n",
            "Epoch 40/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6017 - loss: 0.8685 - val_accuracy: 0.4969 - val_loss: 1.0224\n",
            "Epoch 41/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6149 - loss: 0.8463 - val_accuracy: 0.4990 - val_loss: 1.0243\n",
            "Epoch 42/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6106 - loss: 0.8646 - val_accuracy: 0.5115 - val_loss: 1.0246\n",
            "Epoch 43/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6001 - loss: 0.8763 - val_accuracy: 0.5094 - val_loss: 1.0287\n",
            "Epoch 44/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5929 - loss: 0.8618 - val_accuracy: 0.4969 - val_loss: 1.0365\n",
            "Epoch 45/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5961 - loss: 0.8643 - val_accuracy: 0.5104 - val_loss: 1.0501\n",
            "Epoch 46/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6106 - loss: 0.8698 - val_accuracy: 0.4990 - val_loss: 1.0347\n",
            "Epoch 47/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6105 - loss: 0.8425 - val_accuracy: 0.5021 - val_loss: 1.0500\n",
            "Epoch 48/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6142 - loss: 0.8470 - val_accuracy: 0.4875 - val_loss: 1.0420\n",
            "Epoch 49/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6064 - loss: 0.8478 - val_accuracy: 0.5010 - val_loss: 1.0528\n",
            "Epoch 50/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6066 - loss: 0.8615 - val_accuracy: 0.5042 - val_loss: 1.0566\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Training Accuracy (DNN): 62.50%\n",
            "Testing Accuracy (DNN): 48.42%\n",
            "\n",
            "Classification Report (DNN):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Home Win       0.55      0.72      0.62       557\n",
            "        Draw       0.23      0.10      0.14       303\n",
            "    Away Win       0.45      0.44      0.44       340\n",
            "\n",
            "    accuracy                           0.48      1200\n",
            "   macro avg       0.41      0.42      0.40      1200\n",
            "weighted avg       0.44      0.48      0.45      1200\n",
            "\n",
            "\n",
            "Bookmaker Accuracies on Train Data:\n",
            "B365: 54.31%\n",
            "LB: 54.40%\n",
            "IW: 54.33%\n",
            "WH: 52.79%\n",
            "\n",
            "Bookmaker Accuracies on Test Data:\n",
            "B365: 53.83%\n",
            "LB: 53.83%\n",
            "IW: 54.08%\n",
            "WH: 52.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Network with Bookie Odds"
      ],
      "metadata": {
        "id": "60kn2u-chznB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "file_path = 'updated_final_dataset_with_win_percentages.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Encode the target column (FTR) into numerical values\n",
        "df['FTR_encoded'] = df['FTR'].map({'H': 0, 'D': 1, 'A': 2})\n",
        "\n",
        "# Convert columns (HTFormPtsStr, ATFormPtsStr) to numerical representations\n",
        "df['HTFormPtsStr'] = df['HTFormPtsStr'].apply(\n",
        "    lambda x: sum(3 if ch == 'W' else 1 if ch == 'D' else 0 for ch in x) if isinstance(x, str) else 0\n",
        ")\n",
        "df['ATFormPtsStr'] = df['ATFormPtsStr'].apply(\n",
        "    lambda x: sum(3 if ch == 'W' else 1 if ch == 'D' else 0 for ch in x) if isinstance(x, str) else 0\n",
        ")\n",
        "\n",
        "# Ensure all required columns are numeric and fill NaN values with 0\n",
        "df.fillna(0, inplace=True)\n",
        "\n",
        "# Define feature columns\n",
        "features = [\n",
        "    'Home Win % (Before)', 'Away Win % (Before)',\n",
        "    'HTGS', 'ATGS', 'HTGC', 'ATGC',\n",
        "    'HTFormPts', 'ATFormPts',\n",
        "    'HTWinStreak3', 'HTWinStreak5', 'HTLossStreak3', 'HTLossStreak5',\n",
        "    'ATWinStreak3', 'ATWinStreak5', 'ATLossStreak3', 'ATLossStreak5',\n",
        "    'HTFormPtsStr', 'ATFormPtsStr',\n",
        "    'HomeTeamLP', 'AwayTeamLP',\n",
        "    'DiffLP',\n",
        "    'HTP', 'ATP',\n",
        "    'HTGD', 'ATGD',\n",
        "    'DiffPts', 'DiffFormPts'\n",
        "]\n",
        "target = 'FTR_encoded'\n",
        "\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "# Stratified split to ensure all classes are represented\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert the target variable to categorical format for DNN\n",
        "y_train_categorical = to_categorical(y_train, num_classes=3)\n",
        "y_test_categorical = to_categorical(y_test, num_classes=3)\n",
        "\n",
        "# Define the DNN model\n",
        "model = Sequential([\n",
        "    Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'),\n",
        "    Dropout(0.2),  # Prevent overfitting\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train_categorical,\n",
        "    epochs=50,  # Increase or decrease based on performance\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "train_loss, train_accuracy = model.evaluate(X_train_scaled, y_train_categorical, verbose=0)\n",
        "train_accuracy *= 100\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=0)\n",
        "test_accuracy *= 100\n",
        "\n",
        "# Generate predictions for the test set\n",
        "y_pred_test_prob = model.predict(X_test_scaled)\n",
        "y_pred_test = np.argmax(y_pred_test_prob, axis=1)\n",
        "\n",
        "# Generate classification report\n",
        "class_mapping = {0: 'Home Win', 1: 'Draw', 2: 'Away Win'}\n",
        "target_names = [class_mapping[cls] for cls in sorted(y.unique())]\n",
        "classification_rep = classification_report(y_test, y_pred_test, target_names=target_names)\n",
        "\n",
        "# Bookmaker accuracy calculation\n",
        "def calculate_bookie_accuracy(df_subset, bookies):\n",
        "    accuracies = {}\n",
        "    for bookie in bookies:\n",
        "\n",
        "        bookie_predictions = df_subset[[f\"{bookie}H\", f\"{bookie}D\", f\"{bookie}A\"]].idxmin(axis=1)\n",
        "        bookie_predictions = bookie_predictions.map({f\"{bookie}H\": 'H', f\"{bookie}D\": 'D', f\"{bookie}A\": 'A'})\n",
        "\n",
        "        accuracy = (bookie_predictions == df_subset['FTR']).mean() * 100\n",
        "        accuracies[bookie] = accuracy\n",
        "    return accuracies\n",
        "\n",
        "# Calculate bookmaker accuracies for test data\n",
        "train_indices = X_train.index\n",
        "test_indices = X_test.index\n",
        "bookmakers = ['B365', 'LB', 'IW', 'WH']\n",
        "\n",
        "bookie_accuracies_train = calculate_bookie_accuracy(df.loc[train_indices], bookmakers)\n",
        "bookie_accuracies_test = calculate_bookie_accuracy(df.loc[test_indices], bookmakers)\n",
        "\n",
        "\n",
        "print(f\"Training Accuracy (DNN): {train_accuracy:.2f}%\")\n",
        "print(f\"Testing Accuracy (DNN): {test_accuracy:.2f}%\")\n",
        "print(\"\\nClassification Report (DNN):\")\n",
        "print(classification_rep)\n",
        "\n",
        "print(\"\\nBookmaker Accuracies on Train Data:\")\n",
        "for bookie, accuracy in bookie_accuracies_train.items():\n",
        "    print(f\"{bookie}: {accuracy:.2f}%\")\n",
        "\n",
        "print(\"\\nBookmaker Accuracies on Test Data:\")\n",
        "for bookie, accuracy in bookie_accuracies_test.items():\n",
        "    print(f\"{bookie}: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPfe8z1Ch10Y",
        "outputId": "c9b9bd9a-57a2-469e-da7b-0cbc88069c57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4899 - loss: 1.0270 - val_accuracy: 0.5323 - val_loss: 0.9786\n",
            "Epoch 2/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5385 - loss: 0.9813 - val_accuracy: 0.5208 - val_loss: 0.9809\n",
            "Epoch 3/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5332 - loss: 0.9733 - val_accuracy: 0.5156 - val_loss: 0.9813\n",
            "Epoch 4/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5291 - loss: 0.9821 - val_accuracy: 0.5177 - val_loss: 0.9859\n",
            "Epoch 5/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5442 - loss: 0.9694 - val_accuracy: 0.5240 - val_loss: 0.9810\n",
            "Epoch 6/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5170 - loss: 0.9848 - val_accuracy: 0.5229 - val_loss: 0.9853\n",
            "Epoch 7/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5417 - loss: 0.9635 - val_accuracy: 0.5125 - val_loss: 0.9815\n",
            "Epoch 8/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5406 - loss: 0.9677 - val_accuracy: 0.5146 - val_loss: 0.9824\n",
            "Epoch 9/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5441 - loss: 0.9553 - val_accuracy: 0.5260 - val_loss: 0.9806\n",
            "Epoch 10/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5439 - loss: 0.9639 - val_accuracy: 0.5219 - val_loss: 0.9851\n",
            "Epoch 11/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5554 - loss: 0.9574 - val_accuracy: 0.5146 - val_loss: 0.9842\n",
            "Epoch 12/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5529 - loss: 0.9521 - val_accuracy: 0.5094 - val_loss: 0.9863\n",
            "Epoch 13/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5583 - loss: 0.9414 - val_accuracy: 0.5073 - val_loss: 0.9896\n",
            "Epoch 14/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5477 - loss: 0.9541 - val_accuracy: 0.5240 - val_loss: 0.9912\n",
            "Epoch 15/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5508 - loss: 0.9471 - val_accuracy: 0.5104 - val_loss: 0.9923\n",
            "Epoch 16/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5607 - loss: 0.9363 - val_accuracy: 0.5104 - val_loss: 0.9973\n",
            "Epoch 17/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5532 - loss: 0.9372 - val_accuracy: 0.5094 - val_loss: 0.9950\n",
            "Epoch 18/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5587 - loss: 0.9445 - val_accuracy: 0.5063 - val_loss: 0.9900\n",
            "Epoch 19/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5570 - loss: 0.9317 - val_accuracy: 0.5031 - val_loss: 0.9939\n",
            "Epoch 20/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5588 - loss: 0.9299 - val_accuracy: 0.5063 - val_loss: 0.9908\n",
            "Epoch 21/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5532 - loss: 0.9452 - val_accuracy: 0.5000 - val_loss: 0.9927\n",
            "Epoch 22/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5622 - loss: 0.9257 - val_accuracy: 0.5104 - val_loss: 0.9995\n",
            "Epoch 23/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5684 - loss: 0.9291 - val_accuracy: 0.4927 - val_loss: 1.0017\n",
            "Epoch 24/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5564 - loss: 0.9339 - val_accuracy: 0.5042 - val_loss: 1.0013\n",
            "Epoch 25/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5781 - loss: 0.9195 - val_accuracy: 0.5135 - val_loss: 1.0007\n",
            "Epoch 26/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5626 - loss: 0.9302 - val_accuracy: 0.5021 - val_loss: 1.0037\n",
            "Epoch 27/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5755 - loss: 0.9163 - val_accuracy: 0.4906 - val_loss: 1.0122\n",
            "Epoch 28/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5672 - loss: 0.9095 - val_accuracy: 0.5125 - val_loss: 1.0085\n",
            "Epoch 29/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5722 - loss: 0.9091 - val_accuracy: 0.5031 - val_loss: 1.0008\n",
            "Epoch 30/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5975 - loss: 0.8809 - val_accuracy: 0.5000 - val_loss: 1.0046\n",
            "Epoch 31/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5820 - loss: 0.8962 - val_accuracy: 0.4938 - val_loss: 1.0076\n",
            "Epoch 32/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5531 - loss: 0.9242 - val_accuracy: 0.4948 - val_loss: 1.0057\n",
            "Epoch 33/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5876 - loss: 0.8996 - val_accuracy: 0.4990 - val_loss: 1.0073\n",
            "Epoch 34/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5965 - loss: 0.8816 - val_accuracy: 0.4958 - val_loss: 1.0027\n",
            "Epoch 35/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5907 - loss: 0.8855 - val_accuracy: 0.4792 - val_loss: 1.0186\n",
            "Epoch 36/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5870 - loss: 0.8975 - val_accuracy: 0.4885 - val_loss: 1.0165\n",
            "Epoch 37/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5780 - loss: 0.9038 - val_accuracy: 0.4958 - val_loss: 1.0221\n",
            "Epoch 38/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5871 - loss: 0.8905 - val_accuracy: 0.5063 - val_loss: 1.0317\n",
            "Epoch 39/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5771 - loss: 0.9020 - val_accuracy: 0.5021 - val_loss: 1.0135\n",
            "Epoch 40/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5778 - loss: 0.8749 - val_accuracy: 0.4812 - val_loss: 1.0315\n",
            "Epoch 41/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5928 - loss: 0.8807 - val_accuracy: 0.4854 - val_loss: 1.0287\n",
            "Epoch 42/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5915 - loss: 0.8684 - val_accuracy: 0.4885 - val_loss: 1.0250\n",
            "Epoch 43/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6038 - loss: 0.8589 - val_accuracy: 0.4875 - val_loss: 1.0313\n",
            "Epoch 44/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5940 - loss: 0.8648 - val_accuracy: 0.4865 - val_loss: 1.0374\n",
            "Epoch 45/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5837 - loss: 0.8805 - val_accuracy: 0.4740 - val_loss: 1.0464\n",
            "Epoch 46/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6082 - loss: 0.8594 - val_accuracy: 0.4948 - val_loss: 1.0297\n",
            "Epoch 47/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5966 - loss: 0.8584 - val_accuracy: 0.4885 - val_loss: 1.0353\n",
            "Epoch 48/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6205 - loss: 0.8454 - val_accuracy: 0.4906 - val_loss: 1.0506\n",
            "Epoch 49/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6150 - loss: 0.8420 - val_accuracy: 0.4771 - val_loss: 1.0538\n",
            "Epoch 50/50\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5966 - loss: 0.8604 - val_accuracy: 0.4927 - val_loss: 1.0475\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Training Accuracy (DNN): 61.10%\n",
            "Testing Accuracy (DNN): 48.75%\n",
            "\n",
            "Classification Report (DNN):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Home Win       0.57      0.71      0.63       557\n",
            "        Draw       0.24      0.11      0.15       303\n",
            "    Away Win       0.43      0.46      0.45       340\n",
            "\n",
            "    accuracy                           0.49      1200\n",
            "   macro avg       0.41      0.43      0.41      1200\n",
            "weighted avg       0.45      0.49      0.46      1200\n",
            "\n",
            "\n",
            "Bookmaker Accuracies on Train Data:\n",
            "B365: 54.31%\n",
            "LB: 54.40%\n",
            "IW: 54.33%\n",
            "WH: 52.79%\n",
            "\n",
            "Bookmaker Accuracies on Test Data:\n",
            "B365: 53.83%\n",
            "LB: 53.83%\n",
            "IW: 54.08%\n",
            "WH: 52.50%\n"
          ]
        }
      ]
    }
  ]
}